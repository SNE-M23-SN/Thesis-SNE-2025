# Worker Ansible Role

This Ansible role configures Kubernetes worker nodes and joins them to the cluster established by the master role, providing compute capacity for the DevSecOps platform applications.

## ğŸ¯ **Overview**

The `worker` role is a critical infrastructure component that:

- **Node Configuration**: Sets up worker node hostname and system identification
- **Cluster Integration**: Joins worker nodes to the existing Kubernetes cluster
- **Compute Capacity**: Provides computational resources for application workloads
- **Distributed Architecture**: Enables horizontal scaling and high availability
- **Application Runtime**: Hosts DevSecOps platform applications and services

## ğŸ—ï¸ **Architecture & Integration**

### **Role in DevSecOps Infrastructure**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Common      â”‚    â”‚   Containerd    â”‚    â”‚   Kubernetes    â”‚
â”‚ (System Prep)   â”‚ -> â”‚ (Runtime)       â”‚ -> â”‚ (Base Config)   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ APT Managementâ”‚    â”‚ â€¢ Container     â”‚    â”‚ â€¢ kubelet       â”‚
â”‚ â€¢ Dependencies  â”‚    â”‚ â€¢ CRI Config    â”‚    â”‚ â€¢ Package Hold  â”‚
â”‚ â€¢ System Setup  â”‚    â”‚ â€¢ Security      â”‚    â”‚ â€¢ System Config â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Master      â”‚    â”‚     Worker      â”‚    â”‚   Applications  â”‚
â”‚ (Control Plane) â”‚ -> â”‚ (Compute Node)  â”‚ -> â”‚ (DevSecOps)     â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Join Token    â”‚    â”‚ â€¢ Node Join     â”‚    â”‚ â€¢ LiftOffStage  â”‚
â”‚ â€¢ Cluster Init  â”‚    â”‚ â€¢ Hostname Set  â”‚    â”‚ â€¢ FirstStage    â”‚
â”‚ â€¢ CNI Setup     â”‚    â”‚ â€¢ Cluster Memberâ”‚    â”‚ â€¢ SecondStage   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Worker Node Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Worker Node                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚        System Layer         â”‚       Application Layer       â”‚
â”‚                             â”‚                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ kubelet (Node Agent)      â”‚ â€¢ LiftOffStage Pods           â”‚
â”‚ â€¢ containerd (Runtime)      â”‚ â€¢ FirstStage Pods             â”‚
â”‚ â€¢ CNI (Networking)          â”‚ â€¢ SecondStage Pods            â”‚
â”‚ â€¢ kube-proxy (Networking)   â”‚ â€¢ ThirdStage Pods             â”‚
â”‚ â€¢ Node Hostname             â”‚ â€¢ SAST Platform               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ **Prerequisites**

### **Infrastructure Requirements**
- **Operating System**: Ubuntu 20.04+ with root/sudo access
- **Hardware**: Minimum 2 CPU cores, 4GB RAM, 20GB disk space
- **Network**: Network connectivity to master node
- **Dependencies**: Common, Containerd, and Kubernetes roles must be executed first

### **Required Variables**
- `worker_hostname`: Hostname for the worker node (e.g., "k8sworker")

### **Master Node Requirements**
- **Cluster Initialized**: Master role must be completed successfully
- **Join Token Available**: Master node must have generated join command
- **Network Connectivity**: Worker can reach master node on required ports

## âš™ï¸ **Configuration Variables**

### **ğŸŒ Node Configuration**

| Variable | Default | Description |
|----------|---------|-------------|
| `worker_hostname` | Required | Hostname for the Kubernetes worker node |

### **ğŸ”§ Join Process Configuration**

| Setting | Value | Description |
|---------|-------|-------------|
| Join Command Source | `join-command` | File generated by master role |
| Join Command Location | `/tmp/join-command.sh` | Temporary script location on worker |
| Script Permissions | `0777` | Executable permissions for join script |

## ğŸš€ **Deployment Process**

The Worker role executes a streamlined 3-phase deployment process:

### **Phase 1: Node Identification**
```yaml
# Worker node hostname configuration
1. Sets hostname for worker node identification
2. Ensures proper node naming in cluster
3. Enables node discovery and management
4. Establishes unique node identity
```

### **Phase 2: Join Command Preparation**
```yaml
# Cluster join token and command setup
1. Copies join command from master node
2. Places join script in /tmp/join-command.sh
3. Sets executable permissions (0777)
4. Prepares for cluster integration
```

### **Phase 3: Cluster Integration**
```yaml
# Worker node joins Kubernetes cluster
1. Executes kubeadm join command
2. Establishes connection to master node
3. Registers worker node with cluster
4. Enables workload scheduling on node
```

## ğŸ“– **Usage Examples**

### **Basic Worker Deployment**
```yaml
---
- name: Configure Kubernetes Worker Node
  hosts: worker
  become: yes
  roles:
    - role: common
    - role: containerd
    - role: kubernetes
    - role: worker
  vars:
    worker_hostname: "k8sworker"
```

### **Multiple Worker Nodes**
```yaml
---
- name: Deploy Multiple Kubernetes Workers
  hosts: workers
  become: yes
  roles:
    - role: common
    - role: containerd
    - role: kubernetes
    - role: worker
  vars:
    worker_hostname: "{{ inventory_hostname }}"
```

### **Production Worker Configuration**
```yaml
---
- name: Deploy Production Kubernetes Workers
  hosts: worker_nodes
  become: yes
  roles:
    - role: common
    - role: containerd
    - role: kubernetes
    - role: worker
  vars:
    worker_hostname: "prod-k8s-worker-{{ ansible_host | regex_replace('\\.', '-') }}"
```

### **Development Environment**
```yaml
---
- name: Setup Development Kubernetes Worker
  hosts: worker
  become: yes
  roles:
    - role: common
    - role: containerd
    - role: kubernetes
    - role: worker
  vars:
    worker_hostname: "dev-k8s-worker"
```

## ğŸ”— **Integration with DevSecOps Pipeline**

### **Role Dependencies**
```yaml
# Execution order in main playbook:
1. common                    # System preparation and APT management
2. containerd               # Container runtime configuration
3. kubernetes               # Kubernetes packages and base configuration
4. master                   # Control plane initialization (generates join token)
5. worker                   # THIS ROLE - Worker node cluster joining
6. liftoffstage            # External services deployment
7. firststage-prep         # Application preparation
8. firststage              # Secret detection application
9. secondstage             # AI monitoring and analysis
10. thirdstage             # Dashboard frontend
11. sast                   # Security analysis platform
```

### **Provides for Application Roles**
- **âœ… Compute Capacity**: CPU and memory resources for application pods
- **âœ… Storage Access**: Local and network storage for persistent volumes
- **âœ… Network Connectivity**: Pod networking and service discovery
- **âœ… Container Runtime**: containerd for application container execution
- **âœ… Node Affinity**: Specific node targeting for application placement

### **Hosts DevSecOps Applications**
- **LiftOffStage**: External services (Jenkins, RabbitMQ, PostgreSQL)
- **FirstStage**: Secret detection and security scanning
- **SecondStage**: AI-powered monitoring and analysis
- **ThirdStage**: Dashboard frontend and visualization
- **SAST Platform**: Security analysis tools and Docker runtime

## ğŸš¨ **Troubleshooting Guide**

### **Common Issues & Solutions**

#### **ğŸ”´ Join Command Failures**
```bash
# Check join command file
cat /tmp/join-command.sh
ls -la /tmp/join-command.sh

# Verify master node accessibility
ping <master-node-ip>
telnet <master-node-ip> 6443

# Manual join attempt
sudo kubeadm join <master-ip>:6443 --token <token> --discovery-token-ca-cert-hash <hash>
```

#### **ğŸ”´ Network Connectivity Issues**
```bash
# Check kubelet status
systemctl status kubelet
journalctl -u kubelet -f

# Verify containerd
systemctl status containerd
crictl version

# Check node registration
kubectl get nodes  # (run from master)
```

#### **ğŸ”´ Node Not Ready Status**
```bash
# Check node status from master
kubectl get nodes
kubectl describe node <worker-hostname>

# Check CNI pods
kubectl get pods -n kube-system | grep calico

# Restart kubelet
sudo systemctl restart kubelet
```

### **ğŸ”§ Diagnostic Commands**
```bash
# Node status verification
systemctl status kubelet
systemctl status containerd

# Network connectivity
ping <master-node-ip>
nc -zv <master-node-ip> 6443

# Container runtime
crictl version
crictl ps

# Join command verification
cat /tmp/join-command.sh
```

### **ğŸ”„ Recovery Procedures**
```bash
# Reset worker node
sudo kubeadm reset --force
sudo systemctl restart kubelet
sudo systemctl restart containerd

# Re-run join command
sudo sh /tmp/join-command.sh

# Verify successful join
kubectl get nodes  # (from master)
```

## ğŸ”’ **Security Considerations**

### **Node Security**
- **Join Token Security**: Tokens are time-limited and single-use
- **Certificate Validation**: Automatic CA certificate hash verification
- **Network Security**: Secure communication with master node
- **Container Security**: containerd runtime with security configurations

### **Access Control**
- **Node Isolation**: Worker nodes cannot access master node admin functions
- **RBAC Integration**: Kubernetes Role-Based Access Control enforcement
- **Network Policies**: CNI-based network segmentation and security

## ğŸ“Š **Performance & Monitoring**

### **Node Metrics**
```bash
# Resource usage
kubectl top nodes
kubectl describe node <worker-hostname>

# Pod distribution
kubectl get pods -o wide --all-namespaces

# System resources
free -h
df -h
```

### **Scaling Considerations**
- **Horizontal Scaling**: Additional worker nodes for increased capacity
- **Resource Allocation**: CPU and memory requests/limits for pods
- **Storage Scaling**: Persistent volume provisioning and management
- **Network Scaling**: CNI performance and pod density optimization

## ğŸ“„ **License & Support**

### **License Information**
- **License**: MIT License
- **Author**: Khasan Abdurakhmanov
- **Organization**: Innopolis University DevSecOps Platform
- **Version**: 1.0.0
- **Last Updated**: 2025

---

**ğŸ‰ Thank you for using the Worker Infrastructure Role!**

This role provides essential compute capacity for the DevSecOps platform by joining worker nodes to the Kubernetes cluster. For advanced configurations and enterprise support, please contact the DevSecOps Platform team.
